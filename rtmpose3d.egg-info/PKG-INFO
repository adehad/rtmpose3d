Metadata-Version: 2.1
Name: rtmpose3d
Version: 1.0.0
Summary: RTMPose3D: Real-Time Multi-Person 3D Pose Estimation - Simple PyTorch interface
Home-page: https://github.com/open-mmlab/mmpose
Author: OpenMMLab
Author-email: 
Keywords: pose estimation,3d pose,computer vision,pytorch
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: torch>=2.0.0
Requires-Dist: numpy>=1.20.0
Requires-Dist: opencv-python>=4.5.0
Requires-Dist: mmpose>=1.0.0
Requires-Dist: mmdet>=3.0.0
Requires-Dist: mmcv>=2.0.0
Requires-Dist: mmengine>=0.7.0
Requires-Dist: tqdm>=4.60.0

# RTMPose3D - Standalone Package

**Dead simple 3D pose estimation: numpy array in → 3D keypoints out**

Standalone PyTorch package for RTMPose3D with automatic checkpoint download and caching.

## Installation

```bash
# From the rtmpose3d directory
pip install -e .

# Or directly
cd /path/to/rtmpose3d
python setup.py install
```

## Quick Start

```python
import cv2
from rtmpose3d import RTMPose3DInference

# Initialize (auto-downloads models on first use)
model = RTMPose3DInference(device='cuda:0')

# Run inference
image = cv2.imread('person.jpg')
results = model(image)

# Use results
print(results['keypoints_3d'].shape)  # [N, 133, 3]
```

## Features

✅ **Fully standalone** - All configs and modules bundled  
✅ **Auto-download** - Models download automatically on first use  
✅ **Simple API** - One class, one method call  
✅ **High accuracy** - Uses original PyTorch weights  
✅ **Flexible** - Supports custom configs and checkpoints

## Output Format

```python
{
    'keypoints_3d': np.ndarray,  # Shape: [N, 133, 3] - XYZ coordinates
    'keypoints_2d': np.ndarray,  # Shape: [N, 133, 2] - XY projection
    'scores': np.ndarray,        # Shape: [N, 133] - confidence scores
    'bboxes': np.ndarray         # Shape: [N, 4] - detection boxes
}
```

## Advanced Usage

### Model Size Selection

```python
# Large model (default, best accuracy)
model = RTMPose3DInference(model_size='l')

# Extra large model (higher accuracy, slower)
model = RTMPose3DInference(model_size='x')
```

### Detection Threshold

```python
# Lower threshold = more detections (may include false positives)
results = model(image, bbox_thr=0.1)

# Higher threshold = fewer detections (more conservative)
results = model(image, bbox_thr=0.5)
```

### Custom Cache Directory

```python
model = RTMPose3DInference(
    cache_dir='/path/to/custom/cache'
)
```

### Using Custom Checkpoints

```python
model = RTMPose3DInference(
    detector_checkpoint='/path/to/detector.pth',
    pose_checkpoint='/path/to/pose.pth'
)
```

### Clear Downloaded Checkpoints

```python
from rtmpose3d import clear_cache
clear_cache()  # Removes all cached checkpoints
```

## Keypoint Format

The model outputs **133 keypoints** (COCO-WholeBody format):

- **0-16**: Body keypoints (COCO format)
- **17-22**: Foot keypoints
- **23-90**: Face keypoints (68 points)
- **91-112**: Left hand keypoints (21 points)
- **113-132**: Right hand keypoints (21 points)

### 3D Coordinate System

- **X**: Left-right (negative = left, positive = right)
- **Y**: Depth (negative = closer, positive = farther)  
- **Z**: Up-down (negative = down, positive = up)

## Examples

See `examples/basic_usage.py` for a complete working example.

```bash
python examples/basic_usage.py
```

## Package Structure

```
rtmpose3d/
├── __init__.py          # Package entry point
├── inference.py         # Main RTMPose3DInference class
├── models/             # Custom RTMPose3D modules
│   ├── __init__.py
│   ├── rtmw3d_head.py
│   ├── pose_estimator.py
│   ├── simcc_3d_label.py
│   ├── loss.py
│   └── utils.py
├── configs/            # Model configurations
│   ├── __init__.py
│   ├── rtmdet_m_640-8xb32_coco-person.py
│   ├── rtmw3d-l_8xb64_cocktail14-384x288.py
│   └── rtmw3d-x_8xb32_cocktail14-384x288.py
└── weights/            # Checkpoint management
    ├── __init__.py
    └── downloader.py   # Auto-download utility
```

## Model Info

### RTMW3D-L (Large) - Default
- **Parameters**: ~65M
- **Input**: RGB image (any size, auto-resized)
- **Output**: 133 3D keypoints per person
- **Training**: Cocktail14 dataset

### RTMW3D-X (Extra Large)
- **Parameters**: ~98M  
- **Slightly higher accuracy**
- **Slower inference**

## Cache Location

Models are cached at:
```
~/.cache/rtmpose3d/checkpoints/
```

## Requirements

- Python >= 3.8
- PyTorch >= 2.0.0
- CUDA (recommended for GPU acceleration)
- MMPose >= 1.0.0
- MMDetection >= 3.0.0
- MMCV >= 2.0.0

## Citation

```bibtex
@misc{rtmpose3d2024,
  title={RTMPose3D: Real-Time Multi-Person 3D Pose Estimation},
  author={OpenMMLab},
  year={2024},
  publisher={GitHub},
  howpublished={\url{https://github.com/open-mmlab/mmpose}}
}
```

## License

Apache 2.0

## Acknowledgments

Based on [MMPose](https://github.com/open-mmlab/mmpose) by OpenMMLab.
